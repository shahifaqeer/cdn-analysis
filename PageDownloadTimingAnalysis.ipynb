{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Index page for top 500 alexa websites\n",
    "- Analysis per CDN provider\n",
    "    - time to first byte\n",
    "    - time to DNS resolution\n",
    "    - time to TCP connection\n",
    "    - time to SSL negotiation\n",
    "    - receive time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os, sys, re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'wikipedia.org'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURL Command Example with Output\n",
    "curl -v --trace-time -o /dev/null --connect-timeout 3.0 -w \"\\n\\nContentType: %{content_type}\\nResponseCode: %{response_code}\\nURLEffective: %{url_effective}\\n\\nSizeDownload: %{size_download};\\tSizeRquest: %{size_request}\\nSizeUpload: %{size_upload};\\tSizeHeader: %{size_header}\\n\\nTimeNameLookup: %{time_namelookup}\\nTimeConnect: %{time_connect}\\nTimeAppConnect: %{time_appconnect}\\nTimePreTransfer: %{time_pretransfer}\\nTimeRedirect: %{time_redirect}\\nTimeStartTransfer: %{time_starttransfer}\\nTimeTotal: %{time_total}\\n\" -s https://www.google.co.in\n",
    "\n",
    "\n",
    "12:24:41.186600 * Rebuilt URL to: https://www.google.co.in/  \n",
    "12:24:41.191017 *   Trying 172.217.167.3...  \n",
    "12:24:41.191061 * TCP_NODELAY set  \n",
    "12:24:41.218682 * Connected to www.google.co.in (172.217.167.3) port 443 (#0)  \n",
    "12:24:41.218794 * ALPN, offering h2  \n",
    "12:24:41.218825 * ALPN, offering http/1.1  \n",
    "12:24:41.218890 * Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH  \n",
    "12:24:41.224963 * successfully set certificate verify locations:  \n",
    "12:24:41.224997 *   CAfile: /etc/ssl/cert.pem  \n",
    "  CApath: none  \n",
    "12:24:41.225187 * TLSv1.2 (OUT), TLS handshake, Client hello (1):  \n",
    "12:24:41.225219 } [222 bytes data]  \n",
    "12:24:41.302091 * TLSv1.2 (IN), TLS handshake, Server hello (2):  \n",
    "12:24:41.302182 { [96 bytes data]  \n",
    "12:24:41.302706 * TLSv1.2 (IN), TLS handshake, Certificate (11):  \n",
    "12:24:41.302769 { [3128 bytes data]  \n",
    "12:24:41.309234 * TLSv1.2 (IN), TLS handshake, Server key exchange (12):  \n",
    "12:24:41.309275 { [116 bytes data]  \n",
    "12:24:41.312864 * TLSv1.2 (IN), TLS handshake, Server finished (14):  \n",
    "12:24:41.312896 { [4 bytes data]  \n",
    "12:24:41.313614 * TLSv1.2 (OUT), TLS handshake, Client key exchange (16):  \n",
    "12:24:41.313644 } [37 bytes data]  \n",
    "12:24:41.313695 * TLSv1.2 (OUT), TLS change cipher, Client hello (1):  \n",
    "12:24:41.313723 } [1 bytes data]  \n",
    "12:24:41.313895 * TLSv1.2 (OUT), TLS handshake, Finished (20):  \n",
    "12:24:41.313925 } [16 bytes data]  \n",
    "12:24:41.318727 * TLSv1.2 (IN), TLS change cipher, Client hello (1):  \n",
    "12:24:41.318799 { [1 bytes data]  \n",
    "12:24:41.319048 * TLSv1.2 (IN), TLS handshake, Finished (20):  \n",
    "12:24:41.319106 { [16 bytes data]  \n",
    "12:24:41.319209 * SSL connection using TLSv1.2 / ECDHE-ECDSA-CHACHA20-POLY1305  \n",
    "12:24:41.319265 * ALPN, server accepted to use h2  \n",
    "12:24:41.319324 * Server certificate:  \n",
    "12:24:41.319405 *  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=*.google.com  \n",
    "12:24:41.319470 *  start date: Nov  7 08:59:00 2018 GMT  \n",
    "12:24:41.319525 *  expire date: Jan 30 08:59:00 2019 GMT  \n",
    "12:24:41.319705 *  subjectAltName: host \"www.google.co.in\" matched cert's \"*.google.co.in\"  \n",
    "12:24:41.319858 *  issuer: C=US; O=Google Trust Services; CN=Google Internet Authority G3  \n",
    "12:24:41.319915 *  SSL certificate verify ok.  \n",
    "12:24:41.319996 * Using HTTP2, server supports multi-use  \n",
    "12:24:41.320050 * Connection state changed (HTTP/2 confirmed)  \n",
    "12:24:41.320106 * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0  \n",
    "12:24:41.320264 * Using Stream ID: 1 (easy handle 0x7fb146006600)  \n",
    "12:24:41.320351 > GET / HTTP/2  \n",
    "12:24:41.320351 > Host: www.google.co.in  \n",
    "12:24:41.320351 > User-Agent: curl/7.54.0  \n",
    "12:24:41.320351 > Accept: */*  \n",
    "12:24:41.320351 >  \n",
    "12:24:41.324419 * Connection state changed (MAX_CONCURRENT_STREAMS updated)!  \n",
    "12:24:41.425512 < HTTP/2 200  \n",
    "12:24:41.425586 < date: Tue, 11 Dec 2018 06:54:41 GMT  \n",
    "12:24:41.425637 < expires: -1  \n",
    "12:24:41.425687 < cache-control: private, max-age=0  \n",
    "12:24:41.425741 < content-type: text/html; charset=ISO-8859-1  \n",
    "12:24:41.425793 < p3p: CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"  \n",
    "12:24:41.425845 < server: gws  \n",
    "12:24:41.425897 < x-xss-protection: 1; mode=block  \n",
    "12:24:41.425949 < x-frame-options: SAMEORIGIN  \n",
    "12:24:41.426026 < set-cookie: 1P_JAR=2018-12-11-06; expires=Thu, 10-Jan-2019 06:54:41 GMT; path=/; domain=.google.co.in  \n",
    "12:24:41.426180 < set-cookie: NID=150=pPHcNvIyWCtqTFQg8ywE9W6ZJEq7IgUcIdKsn5Od5SUcrW19sHBUblridrGt7zMn9IyRgUhJqvrJ0Hw5B9kkW51nJMsBQ9yTzwCtUYZUnGKq5E7sD5X7zNKmNXV7mmljGbb9CIqk1XigbExIVNozjA9uO_BJoPaO5gW93g_Z91I; expires=Wed, 12-Jun-2019 06:54:41 GMT; path=/; domain=.google.co.in; HttpOnly  \n",
    "12:24:41.426250 < alt-svc: quic=\":443\"; ma=2592000; v=\"44,43,39,35\"  \n",
    "12:24:41.426303 < accept-ranges: none  \n",
    "12:24:41.426377 < vary: Accept-Encoding  \n",
    "12:24:41.426457 <  \n",
    "12:24:41.426640 { [1388 bytes data]  \n",
    "12:24:41.428591 * Connection #0 to host www.google.co.in left intact  \n",
    "\n",
    "\n",
    "\n",
    "ContentType: text/html; charset=ISO-8859-1  \n",
    "ResponseCode: 200  \n",
    "URLEffective: https://www.google.co.in/  \n",
    "\n",
    "\n",
    "\n",
    "SizeDownload: 13548;\tSizeRquest: 78  \n",
    "SizeUpload: 0;\tSizeHeader: 759  \n",
    "\n",
    "\n",
    "\n",
    "TimeNameLookup: 0.004405  \n",
    "TimeConnect: 0.032078  \n",
    "TimeAppConnect: 0.133374  \n",
    "TimePreTransfer: 0.133973  \n",
    "TimeRedirect: 0.000000  \n",
    "TimeStartTransfer: 0.240047  \n",
    "TimeTotal: 0.241995  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarding curl timings from https://ec.haxx.se/usingcurl-verbose.html:  \n",
    "\n",
    "%{time_appconnect} shows the time, in seconds, it took from the start until the SSL/SSH/etc connect/handshake to the remote host was completed.  \n",
    "\n",
    "%{time_connect} shows the time, in seconds, it took from the start until the TCP connect to the remote host (or proxy) was completed.  \n",
    "\n",
    "%{time_namelookup} shows the time, in seconds, it took from the start until the name resolving was completed.  \n",
    "\n",
    "%{time_pretransfer} shows the time, in seconds, it took from the start until the file transfer was just about to begin. This includes all pre-transfer commands and negotiations that are specific to the particular protocol(s) involved.  \n",
    "\n",
    "%{time_redirect} shows the time, in seconds, it took for all redirection steps including name lookup, connect, pre-transfer and transfer before the final transaction was started. time_redirect shows the complete execution time for multiple redirections.  \n",
    "\n",
    "%{time_starttransfer} shows the time, in seconds, it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result.  \n",
    "\n",
    "%{time_total} shows the total time, in seconds, that the full operation lasted. The time will be displayed with millisecond resolution.  \n",
    "\n",
    "### Calculate Timings\n",
    "\n",
    "T0 = timer.start()    \n",
    "Tf = timer.stop()  \n",
    "\n",
    "\n",
    "if not using HTTPS/SSL: time_appconnect returned is 0, so set time_appconnect = time_connect\n",
    "\n",
    "t_dns = time for DNS resolution (no redirects) = time_namelookup - time_redirect  \n",
    "t_tcp = time for TCP connection (SYN/SYNACK) = time_connect - time_namelookup  \n",
    "t_ssl = time for SSL handshake (only if https) = time_appconnect - time_connect  \n",
    "t_fbyte = time_starttransfer\n",
    "t_wait = time between issuing GET request and first byte received = time_starttransfer - time_pretransfer  \n",
    "t_rx = time to receive data from first to last byte = time_total - time_starttransfer  \n",
    "\n",
    "\n",
    "t_calc = waiting time between SSL and GET request = time_pretransfer - time_appconnect  \n",
    "t_start = waiting time between issuing curl command and issuing first byte of data for DNS lookup  \n",
    "t_stop = waiting time between receiving last byte and ending the curl command  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'wikipedia.org'\n",
    "url = 'https://www.'+site+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url_effective': 'https://www.wikipedia.org/',\n",
       " 'response_code': 200,\n",
       " 'time_namelookup': 0.004959,\n",
       " 'time_connect': 0.163835,\n",
       " 'time_appconnect': 0.368026,\n",
       " 'time_pretransfer': 0.36818,\n",
       " 'time_redirect': 0.0,\n",
       " 'time_starttransfer': 0.951108,\n",
       " 'time_total': 1.299881}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import sys\n",
    "import json\n",
    "#import re\n",
    "\n",
    "# useful when threading\n",
    "#sys.stdout.write(\".\")\n",
    "#sys.stdout.flush()\n",
    "\n",
    "p = subprocess.Popen(['curl', '-w', '@curl_time_format.txt', '-o', '/dev/null', '-s', url], stdout=subprocess.PIPE)\n",
    "out, err = p.communicate()\n",
    "\n",
    "# convert output string to python dict using json\n",
    "json.loads(out.decode('UTF-8'))\n",
    "\n",
    "#out = re.sub(r'(\\d+),(\\d+)', r'\\1.\\2', out.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "#from multiprocessing.pool import ThreadPool\n",
    "#import numpy as np\n",
    "#import session\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "list_of_websites = 'top-1m-new.csv' # location of alexa top websites as RANK,SITE\\n\n",
    "count = 10     # average timings over count loops of curl requests\n",
    "nthreads = 2 # number of parallel threads for same url\n",
    "# for each website COUNT time queries (in parallel)?\n",
    "# for each result.response_code == '200' -> add to dict and find avg timings per website\n",
    "\n",
    "\n",
    "def fetch_url(url):\n",
    "    '''fetch url using curl\n",
    "    connection timeout of 3.0 seconds\n",
    "    result is [ dict {url_effective, response_code, time_namelookup, time_connect, time_appconnect,\n",
    "    time_pretransfer, time_redirect, time_starttransfer, time_total}, error, exception ]\n",
    "    '''\n",
    "    try:\n",
    "        p = subprocess.Popen(['curl', '--connect-timeout', '3.0', '-o', '/dev/null',  '-w', '@curl_time_format.txt',\n",
    "                              '-s', url], stdout=subprocess.PIPE)\n",
    "        out, err = p.communicate()\n",
    "        result = json.loads(out.decode('UTF-8'))\n",
    "        print(\"%r (%r) fetched with response code %r in %ss\"\n",
    "              % (url, result['url_effective'], result['response_code'], result['time_total']))    \n",
    "    except Exception as e:\n",
    "        print(\"Error fetching %r: Exception %s\"\n",
    "              % (url, e))\n",
    "        result = None\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_list(websites, nwebsites=500):\n",
    "    \"\"\"get top 500 of alexa websites csv <RANK, SITE> and append with 'https://www.' for curl request\"\"\"\n",
    "    urls = defaultdict(int)\n",
    "    from itertools import islice\n",
    "    with open(websites) as f:\n",
    "        for line in islice(f, nwebsites):\n",
    "            rank, site = line.strip().split(',')\n",
    "            url = 'https://www.' + site + '/'\n",
    "            urls[rank] = url\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1():\n",
    "\n",
    "    list_of_websites = 'top-1m-new.csv'  # location of alexa top websites as RANK,SITE\\n\n",
    "    count = 3  # average timings over count loops of curl requests\n",
    "    nthreads = 3 # number of parallel threads for same url\n",
    "\n",
    "    data = defaultdict(list)    # save result as json and load in pandas for averaging and analysis\n",
    "    urls = load_url_list(list_of_websites, 5)\n",
    "    url_counter = 0\n",
    "\n",
    "    for rank, url in urls.items():\n",
    "\n",
    "        url_counter += 1\n",
    "        urls_parallel = [url for i in range(count)]\n",
    "        print(\"Start time: %s, URL: %r, Rank: %s\" % (time.time(), url, rank))\n",
    "\n",
    "        pool = multiprocessing.Pool(processes=nthreads)\n",
    "        pool_outputs = pool.map(fetch_url, urls_parallel)  # pool_output is a list of results\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        for res in pool_outputs:\n",
    "            if res is not None:\n",
    "                [data[key].append(res[key]) for key in res.keys()]\n",
    "                data['rank'].append(rank)\n",
    "\n",
    "    #with open('output/curl-timing-data-test.json', 'w') as outfile:\n",
    "    #    json.dump(data, outfile)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 1544600289.998162, URL: 'https://www.google.com/', Rank: 1\n",
      "'https://www.google.com/' ('https://www.google.com/') fetched with response code '302' in 0.5846s\n",
      "'https://www.google.com/' ('https://www.google.com/') fetched with response code '302' in 0.730209s\n",
      "'https://www.google.com/' ('https://www.google.com/') fetched with response code '302' in 0.741777s\n",
      "Start time: 1544600290.830642, URL: 'https://www.youtube.com/', Rank: 2\n",
      "'https://www.youtube.com/' ('https://www.youtube.com/') fetched with response code '200' in 1.25057s\n",
      "'https://www.youtube.com/' ('https://www.youtube.com/') fetched with response code '200' in 1.369272s\n",
      "'https://www.youtube.com/' ('https://www.youtube.com/') fetched with response code '200' in 1.89307s\n",
      "Start time: 1544600292.8194282, URL: 'https://www.facebook.com/', Rank: 3\n",
      "'https://www.facebook.com/' ('https://www.facebook.com/') fetched with response code '200' in 1.39442s\n",
      "'https://www.facebook.com/' ('https://www.facebook.com/') fetched with response code '200' in 1.462463s\n",
      "'https://www.facebook.com/' ('https://www.facebook.com/') fetched with response code '200' in 1.627038s\n",
      "Start time: 1544600294.579304, URL: 'https://www.baidu.com/', Rank: 4\n",
      "'https://www.baidu.com/' ('https://www.baidu.com/') fetched with response code '200' in 0.4416s\n",
      "'https://www.baidu.com/' ('https://www.baidu.com/') fetched with response code '200' in 0.44981s\n",
      "'https://www.baidu.com/' ('https://www.baidu.com/') fetched with response code '200' in 0.458143s\n",
      "Start time: 1544600295.111506, URL: 'https://www.wikipedia.org/', Rank: 5\n",
      "'https://www.wikipedia.org/' ('https://www.wikipedia.org/') fetched with response code '200' in 0.582499s\n",
      "'https://www.wikipedia.org/' ('https://www.wikipedia.org/') fetched with response code '200' in 0.58965s\n",
      "'https://www.wikipedia.org/' ('https://www.wikipedia.org/') fetched with response code '200' in 0.594588s\n"
     ]
    }
   ],
   "source": [
    "d = main1()\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
